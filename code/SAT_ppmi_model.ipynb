{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import vsm\n",
    "import data_loading\n",
    "import nlu_utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing co-occurence matrix\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "sat = data_loading.SAT()\n",
    "dev = sat.dev()\n",
    "gutenberg = sat.train_word_word_cooccurence(window=5, vocab_size=10000, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>of</th>\n",
       "      <th>to</th>\n",
       "      <th>gonna</th>\n",
       "      <th>in</th>\n",
       "      <th>i</th>\n",
       "      <th>he</th>\n",
       "      <th>was</th>\n",
       "      <th>have</th>\n",
       "      <th>...</th>\n",
       "      <th>strung</th>\n",
       "      <th>bounding</th>\n",
       "      <th>accomplishments</th>\n",
       "      <th>wee</th>\n",
       "      <th>inflict</th>\n",
       "      <th>denial</th>\n",
       "      <th>gratifying</th>\n",
       "      <th>arouse</th>\n",
       "      <th>clustered</th>\n",
       "      <th>acceptable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1150758</td>\n",
       "      <td>1546998</td>\n",
       "      <td>2303638</td>\n",
       "      <td>1025809</td>\n",
       "      <td>546682</td>\n",
       "      <td>857167</td>\n",
       "      <td>381270</td>\n",
       "      <td>431674</td>\n",
       "      <td>567239</td>\n",
       "      <td>459783</td>\n",
       "      <td>...</td>\n",
       "      <td>232</td>\n",
       "      <td>350</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>196</td>\n",
       "      <td>186</td>\n",
       "      <td>206</td>\n",
       "      <td>250</td>\n",
       "      <td>412</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1546998</td>\n",
       "      <td>285101</td>\n",
       "      <td>732932</td>\n",
       "      <td>611510</td>\n",
       "      <td>521166</td>\n",
       "      <td>385879</td>\n",
       "      <td>282628</td>\n",
       "      <td>305280</td>\n",
       "      <td>309942</td>\n",
       "      <td>252834</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>232</td>\n",
       "      <td>198</td>\n",
       "      <td>168</td>\n",
       "      <td>102</td>\n",
       "      <td>112</td>\n",
       "      <td>106</td>\n",
       "      <td>122</td>\n",
       "      <td>212</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>2303638</td>\n",
       "      <td>732932</td>\n",
       "      <td>203382</td>\n",
       "      <td>372685</td>\n",
       "      <td>568559</td>\n",
       "      <td>353957</td>\n",
       "      <td>185758</td>\n",
       "      <td>187258</td>\n",
       "      <td>247891</td>\n",
       "      <td>205648</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>206</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>198</td>\n",
       "      <td>160</td>\n",
       "      <td>90</td>\n",
       "      <td>148</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1025809</td>\n",
       "      <td>611510</td>\n",
       "      <td>372685</td>\n",
       "      <td>180858</td>\n",
       "      <td>335890</td>\n",
       "      <td>209907</td>\n",
       "      <td>333130</td>\n",
       "      <td>281440</td>\n",
       "      <td>245218</td>\n",
       "      <td>282880</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>82</td>\n",
       "      <td>98</td>\n",
       "      <td>72</td>\n",
       "      <td>254</td>\n",
       "      <td>82</td>\n",
       "      <td>180</td>\n",
       "      <td>308</td>\n",
       "      <td>40</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gonna</th>\n",
       "      <td>546682</td>\n",
       "      <td>521166</td>\n",
       "      <td>568559</td>\n",
       "      <td>335890</td>\n",
       "      <td>132512</td>\n",
       "      <td>307890</td>\n",
       "      <td>184868</td>\n",
       "      <td>199682</td>\n",
       "      <td>246220</td>\n",
       "      <td>192138</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>244</td>\n",
       "      <td>104</td>\n",
       "      <td>146</td>\n",
       "      <td>82</td>\n",
       "      <td>68</td>\n",
       "      <td>82</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           the      and       of       to   gonna      in       i      he  \\\n",
       "the    1150758  1546998  2303638  1025809  546682  857167  381270  431674   \n",
       "and    1546998   285101   732932   611510  521166  385879  282628  305280   \n",
       "of     2303638   732932   203382   372685  568559  353957  185758  187258   \n",
       "to     1025809   611510   372685   180858  335890  209907  333130  281440   \n",
       "gonna   546682   521166   568559   335890  132512  307890  184868  199682   \n",
       "\n",
       "          was    have     ...      strung  bounding  accomplishments  wee  \\\n",
       "the    567239  459783     ...         232       350              188  190   \n",
       "and    309942  252834     ...         182       232              198  168   \n",
       "of     247891  205648     ...          92        84              206   76   \n",
       "to     245218  282880     ...         108        82               98   72   \n",
       "gonna  246220  192138     ...         118        70               66  244   \n",
       "\n",
       "       inflict  denial  gratifying  arouse  clustered  acceptable  \n",
       "the        196     186         206     250        412         188  \n",
       "and        102     112         106     122        212         112  \n",
       "of          78     198         160      90        148          52  \n",
       "to         254      82         180     308         40         218  \n",
       "gonna      104     146          82      68         82          70  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PPMI matrix\n",
    "guten_ppmi = vsm.pmi(gutenberg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>of</th>\n",
       "      <th>to</th>\n",
       "      <th>gonna</th>\n",
       "      <th>in</th>\n",
       "      <th>i</th>\n",
       "      <th>he</th>\n",
       "      <th>was</th>\n",
       "      <th>have</th>\n",
       "      <th>...</th>\n",
       "      <th>strung</th>\n",
       "      <th>bounding</th>\n",
       "      <th>accomplishments</th>\n",
       "      <th>wee</th>\n",
       "      <th>inflict</th>\n",
       "      <th>denial</th>\n",
       "      <th>gratifying</th>\n",
       "      <th>arouse</th>\n",
       "      <th>clustered</th>\n",
       "      <th>acceptable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095674</td>\n",
       "      <td>0.650401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052528</td>\n",
       "      <td>0.471021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106221</td>\n",
       "      <td>0.654601</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.095674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321350</td>\n",
       "      <td>0.571378</td>\n",
       "      <td>0.417991</td>\n",
       "      <td>0.315588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501717</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.650401</td>\n",
       "      <td>0.016762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252723</td>\n",
       "      <td>0.056644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567210</td>\n",
       "      <td>0.344049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088823</td>\n",
       "      <td>0.053915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553999</td>\n",
       "      <td>1.075133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gonna</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.252723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178700</td>\n",
       "      <td>0.235004</td>\n",
       "      <td>0.595905</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041759</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            the       and        of   to     gonna        in         i  \\\n",
       "the    0.000000  0.095674  0.650401  0.0  0.000000  0.272996  0.000000   \n",
       "and    0.095674  0.000000  0.016762  0.0  0.009134  0.000000  0.000000   \n",
       "of     0.650401  0.016762  0.000000  0.0  0.252723  0.056644  0.000000   \n",
       "to     0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.088823   \n",
       "gonna  0.000000  0.009134  0.252723  0.0  0.000000  0.250567  0.000000   \n",
       "\n",
       "             he       was      have     ...        strung  bounding  \\\n",
       "the    0.000000  0.047458  0.000000     ...      0.052528  0.471021   \n",
       "and    0.000000  0.000000  0.000000     ...      0.321350  0.571378   \n",
       "of     0.000000  0.000000  0.000000     ...      0.000000  0.000000   \n",
       "to     0.053915  0.000000  0.109742     ...      0.048194  0.000000   \n",
       "gonna  0.000000  0.214365  0.000000     ...      0.377937  0.000000   \n",
       "\n",
       "       accomplishments       wee   inflict    denial  gratifying    arouse  \\\n",
       "the           0.000000  0.000000  0.000000  0.000000    0.000000  0.106221   \n",
       "and           0.417991  0.315588  0.000000  0.000000    0.000000  0.000000   \n",
       "of            0.614153  0.000000  0.000000  0.567210    0.344049  0.000000   \n",
       "to            0.000000  0.000000  0.886758  0.000000    0.553999  1.075133   \n",
       "gonna         0.000000  1.178700  0.235004  0.595905    0.008951  0.000000   \n",
       "\n",
       "       clustered  acceptable  \n",
       "the     0.654601    0.000000  \n",
       "and     0.501717    0.000000  \n",
       "of      0.298896    0.000000  \n",
       "to      0.000000    0.744425  \n",
       "gonna   0.041759    0.000000  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guten_ppmi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPMIModel:\n",
    "    def __init__(self, corpus_pmi, try_synonyms=True, verbose=False):\n",
    "        self.corpus_pmi = corpus_pmi\n",
    "        self.try_synonyms = try_synonyms\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def answer(self, problem):\n",
    "        n_blanks = problem['num_blanks']\n",
    "        if n_blanks == 1:\n",
    "            return self.answer1(problem)\n",
    "        else: # n_blanks == 2\n",
    "            return self.answer2(problem)\n",
    "    \n",
    "    def answer1(self, problem):\n",
    "        for option1 in problem[\"candidates\"]:\n",
    "            scores += [self.score1(problem[\"question\"], option1)]\n",
    "        return [np.argmax(scores)]\n",
    "\n",
    "    \n",
    "    def approx_ppmi(self, proposal_token, proposal_synonyms, word_token):\n",
    "        pos = nlu_utils.spacy_to_wn_tag(word_token.pos_)\n",
    "        word_synonyms = nlu_utils.get_alternate_words(word_token.norm_, pos)\n",
    "        # try matching using different versions of the proposal word\n",
    "        for psyn in proposal_synonyms:\n",
    "            score = self.ppmi(psyn, word_token.norm_)\n",
    "            if score is not None:\n",
    "                if self.verbose:\n",
    "                    print(\"Used synonym for proposal word: {} -> {}\".format(proposal_token.text, psyn))\n",
    "                return score\n",
    "        # try matching using different versions of the non-proposal word\n",
    "        for wsyn in word_synonyms:\n",
    "            score = self.ppmi(wsyn, proposal_token.norm_)\n",
    "            if score is not None:\n",
    "                if self.verbose:\n",
    "                    print(\"Used synonym: {} -> {}\".format(word_token.text, wsyn))\n",
    "                return score\n",
    "        # Next just try all combos\n",
    "        for psyn in proposal_synonyms:\n",
    "            for wsyn in word_synonyms:\n",
    "                score = self.ppmi(psyn, word_token.norm_)\n",
    "                if score is not None:\n",
    "                    if self.verbose:\n",
    "                        print(\"Used synonym: {} -> {} and {} -> {}\".format(proposal_token.text, psyn, word_token.text, wsyn))\n",
    "                    return score\n",
    "        if self.verbose:\n",
    "            print(\"UNABLE TO FIND ANY SYNONYMS IN VOCABULARY\")\n",
    "        return None\n",
    "\n",
    "    def ppmi(self, proposal, word):\n",
    "        try:\n",
    "            return self.corpus_pmi.loc[proposal, word]\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "    def substitute(self, sentence, proposal):\n",
    "        sentence_list = sentence.split()\n",
    "        i = sentence_list.index('_____')\n",
    "        sentence_list[i] = proposal\n",
    "        return ' '.join(sentence_list)\n",
    "\n",
    "    def score1(self, sentence, proposal):\n",
    "        full_sentence = self.substitute(sentence, proposal)\n",
    "        doc = nlu_utils.get_spacy_doc(full_sentence)\n",
    "        _, proposal_token = nlu_utils.get_token(doc, proposal)\n",
    "\n",
    "        if self.try_synonyms:\n",
    "            pos = nlu_utils.spacy_to_wn_tag(proposal_token.pos_)\n",
    "            synonyms = nlu_utils.get_alternate_words(proposal_token.norm_, pos)\n",
    "\n",
    "        tot_score = 0\n",
    "        for token in doc:\n",
    "            if token == proposal_token:  # !!! This is dubious (might be 'is', not ==)\n",
    "                continue\n",
    "            if token.is_punct or token.is_space:\n",
    "                continue\n",
    "            score = self.ppmi(proposal_token.norm_, token.norm_)\n",
    "            if score is None and self.try_synonyms:\n",
    "                score = self.approx_ppmi(proposal_token, synonyms, token)\n",
    "            tot_score += score if score is not None else 0\n",
    "        return tot_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "BLANK_0\n",
      "of\n",
      "the\n",
      "scientist\n",
      "'s\n",
      "rebuttal\n",
      "of\n",
      "the\n",
      "hypothesis\n",
      "was\n",
      "startling\n",
      "even\n",
      "in\n",
      "the\n",
      "notoriously\n",
      "$\n",
      "BLANK1\n",
      "world\n",
      "of\n",
      "nineteenth\n",
      "-\n",
      "century\n",
      "geology\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlu_utils.get_spacy_doc(\"The BLANK_0 of the scientist's rebuttal of the hypothesis was startling even in the notoriously $BLANK1 world of nineteenth-century geology.\")\n",
    "for token in doc: print (token)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
